{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0115653-642a-4fff-928b-f3f21fae8d24",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### 劃分資料集 ###\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "data = pd.read_csv('lasso.csv')\n",
    "\n",
    "X = data.drop('mace', axis=1)\n",
    "y = data['mace']\n",
    "\n",
    "# 分割訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# 將未平衡處理的訓練集保存為CSV文件\n",
    "unbalanced_train_data = pd.DataFrame(X_train, columns=X.columns)\n",
    "unbalanced_train_data['mace'] = y_train\n",
    "unbalanced_train_data.to_csv('unbalanced_train_lasso.csv', index=False)\n",
    "\n",
    "# 進行隨機欠抽樣平衡處理\n",
    "rus = RandomUnderSampler()\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 將平衡後的訓練集轉換為 DataFrame 並保存為CSV文件\n",
    "resampled_data = pd.DataFrame(X_train_resampled, columns=X.columns)\n",
    "resampled_data['mace'] = y_train_resampled\n",
    "resampled_data.to_csv('balanced_train_lasso.csv', index=False)\n",
    "\n",
    "# 將測試集轉換為 DataFrame 並保存為CSV文件\n",
    "test_data = pd.DataFrame(X_test, columns=X.columns)\n",
    "test_data['mace'] = y_test\n",
    "test_data.to_csv('test_lasso.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67135e80-6be6-4c44-9492-f94eeafd97b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## SVM五折交叉&測試集驗證 ##\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_model(train_file, test_file):\n",
    "    train_data = pd.read_csv(train_file)\n",
    "    X_train = train_data.drop('mace', axis=1)\n",
    "    y_train = train_data['mace']\n",
    "\n",
    "    svm_model = SVC(probability=True)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    precision_scores = cross_val_score(svm_model, X_train, y_train, cv=cv, scoring='precision')\n",
    "    recall_scores = cross_val_score(svm_model, X_train, y_train, cv=cv, scoring='recall')\n",
    "    f1_scores = cross_val_score(svm_model, X_train, y_train, cv=cv, scoring='f1')\n",
    "    roc_auc_scores = cross_val_score(svm_model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "\n",
    "    # Print cross-validation results\n",
    "    print(\"Average Precision: %0.4f\" % precision_scores.mean())\n",
    "    print(\"Average Recall: %0.4f\" % recall_scores.mean())\n",
    "    print(\"Average F1: %0.4f\" % f1_scores.mean())\n",
    "    print(\"Average ROC AUC: %0.4f\" % roc_auc_scores.mean())\n",
    "\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    X_test = test_data.drop('mace', axis=1)\n",
    "    y_test = test_data['mace']\n",
    "\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_pred_proba = svm_model.predict_proba(X_test)[:, 1] \n",
    "\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(\"_____Test Set Evaluation Metrics_____\")\n",
    "    print(\"Precision: %0.4f\" % precision)\n",
    "    print(\"Recall: %0.4f\" % recall)\n",
    "    print(\"F1: %0.4f\" % f1)\n",
    "    print(\"ROC AUC: %0.4f\" % roc_auc)\n",
    "\n",
    "# evaluate_model('bert_balanced.csv', 'test_bert.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c6a71-eb43-467f-bdac-2bd9e71ff058",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## XGBoost 五折交叉&測試集驗證 ##\n",
    "def evaluate_model(train_file, test_file):\n",
    "    train_data = pd.read_csv(train_file)\n",
    "    X_train = train_data.drop('mace', axis=1)\n",
    "    y_train = train_data['mace']\n",
    "\n",
    "\n",
    "    xgb_model = XGBClassifier()\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    precision_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='precision')\n",
    "    recall_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='recall')\n",
    "    f1_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='f1')\n",
    "    roc_auc_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "\n",
    "    print(\"Average Precision: %0.4f\" % precision_scores.mean())\n",
    "    print(\"Average Recall: %0.4f\" % recall_scores.mean())\n",
    "    print(\"Average F1: %0.4f\" % f1_scores.mean())\n",
    "    print(\"Average ROC AUC: %0.4f\" % roc_auc_scores.mean())\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    test_data = pd.read_csv(test_file)\n",
    "    X_test = test_data.drop('mace', axis=1)\n",
    "    y_test = test_data['mace']\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    print(\"_____Test Set Evaluation Metrics_____\")\n",
    "    print(\"Precision: %0.4f\" % precision)\n",
    "    print(\"Recall: %0.4f\" % recall)\n",
    "    print(\"F1: %0.4f\" % f1)\n",
    "    print(\"ROC AUC: %0.4f\" % roc_auc)\n",
    "    \n",
    "#evaluate_model('bert_balanced.csv', 'test_bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f84def-8795-4d75-bff2-f762da8f3eac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## GEV-NN五折交叉驗證 ##\n",
    "import numpy as np\n",
    "from Gev_network import MLP_AE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 150\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "def one_hot_encoding(train, variable):\n",
    "    values = train[variable].unique()\n",
    "    if len(values)==2:\n",
    "        train[str(values[0])] = np.where(train[variable] == values[0], 1, 0)\n",
    "        train = train.drop(variable, axis=1)\n",
    "    else:\n",
    "        for val in values:\n",
    "            train[str(val)] = np.where(train[variable]==val, 1, 0)\n",
    "        train = train.drop(variable, axis=1)\n",
    "\n",
    "    return train\n",
    "\n",
    "\n",
    "def training (activation, loss_weight, data_name):\n",
    "\n",
    "    res = {'activation': [], 'data': [], 'weight': [], 'acc': [],  'precision': [],\n",
    "             'recall': [], 'f-score': [] ,'auc_score': []}\n",
    "\n",
    "    data = pd.read_csv(data_name+'.csv')\n",
    "\n",
    "    for var in list(data):\n",
    "        if data[var].dtype == 'object':\n",
    "            data = one_hot_encoding(data, var)\n",
    "\n",
    "    data = np.asarray(data)\n",
    "\n",
    "    length = data.shape[1] - 1\n",
    "    X, Y = data[:, 0:length], data[:, length]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler = scaler.fit(X)\n",
    "    scaled_X = scaler.transform(np.asarray(X))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    data_index = 1\n",
    "\n",
    "    for train_index, test_index in skf.split(scaled_X, Y):\n",
    "\n",
    "        trainX, testX = scaled_X[train_index], scaled_X[test_index]\n",
    "        trainY, testY = Y[train_index], Y[test_index]\n",
    "\n",
    "        batch_size = 16\n",
    "\n",
    "\n",
    "        for weight in loss_weight:\n",
    "           model = MLP_AE(trainX=trainX, trainY=trainY, epoch_number=2000, batch_size=batch_size, learning_rate=0.001,\n",
    "                          encoder=[32, 16, 8],decoder=[16, 32], sofnn=[32], early_stoppting_patience=200,\n",
    "                          neurons=[32], activation=activation, reg_lambda=0.00001,\n",
    "                          loss_weigth=weight, rand=data_index)\n",
    "\n",
    "           final_model = model.MLP_AE('GEV_MODEL/test1/model_ae_%s_%s' %(data_name, data_index),\n",
    "                                      'GEV_MODEL/test1/model_%s_%s_%s_%s.tf' %(data_name, activation, data_index, weight))\n",
    "\n",
    "           pred_Y, true_Y = model.predict(testX, testY, final_model)\n",
    "\n",
    "           recall, auc_score, f_score, acc, precision = model.model_evaluation(pred_Y, true_Y)\n",
    "\n",
    "           print(\"%s: 'recall' %0.4f, 'AUC', %0.4f, 'F', %0.4f, 'ACC', %0.4f, \"\n",
    "                 \"'precision', %0.4f\" %(data_name, recall, auc_score, f_score, acc, precision))\n",
    "\n",
    "           res['activation'].append(activation)\n",
    "           res['data'].append(data_name)\n",
    "           res['precision'].append(precision)\n",
    "           res['auc_score'].append(auc_score)\n",
    "           res['acc'].append(acc)\n",
    "           res['f-score'].append(f_score)\n",
    "           res['recall'].append(recall)\n",
    "           res['weight'].append(weight)\n",
    "\n",
    "           data_index = data_index + 1\n",
    "\n",
    "    res_brier = pd.DataFrame.from_dict(res)\n",
    "\n",
    "    res_brier.to_csv('GEV_MODEL/' + 'result_final.csv', mode='a',\n",
    "                     encoding='euc-kr', index=False)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "loss_weight= [0.05]\n",
    "\n",
    "# 放入檔案\n",
    "data_names = ['']\n",
    "for data_name in data_names:\n",
    "    result_gev = training(activation='gev',loss_weight=loss_weight,data_name=data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe9236-d0f9-4c7f-bf47-c78da4982908",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## GEV-NN測試集驗證 ##\n",
    "\n",
    "from Gev_network import MLP_AE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "def one_hot_encoding(data, variable):\n",
    "    values = data[variable].unique()\n",
    "    if len(values) == 2:\n",
    "        data[str(values[0])] = np.where(data[variable] == values[0], 1, 0)\n",
    "        data = data.drop(variable, axis=1)\n",
    "    else:\n",
    "        for val in values:\n",
    "            data[str(val)] = np.where(data[variable] == val, 1, 0)\n",
    "        data = data.drop(variable, axis=1)\n",
    "    return data\n",
    "\n",
    "def training(activation, loss_weight, data_name):\n",
    "    res = {'activation': [], 'data': [], 'weight': [], 'acc': [],  'precision': [],\n",
    "           'recall': [], 'f-score': [], 'auc_score': []}\n",
    "\n",
    "    data = pd.read_csv(data_name + '.csv')\n",
    "\n",
    "    for var in list(data):\n",
    "        if data[var].dtype == 'object':\n",
    "            data = one_hot_encoding(data, var)\n",
    "\n",
    "    data = np.asarray(data)\n",
    "    length = data.shape[1] - 1\n",
    "    X, Y = data[:, :length], data[:, length]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "    model = MLP_AE(trainX=scaled_X, trainY=Y, epoch_number=2000, batch_size=16, learning_rate=0.001,\n",
    "                   encoder=[32, 16, 8], decoder=[16, 32], sofnn=[32], early_stoppting_patience=200,\n",
    "                   neurons=[32], activation=activation, reg_lambda=0.00001,\n",
    "                   loss_weigth=loss_weight, rand=1)\n",
    "\n",
    "    final_model = model.MLP_AE('GEV_MODEL/new_test/model_ae_%s' % data_name,\n",
    "                               'GEV_MODEL/new_test/model_%s_%s.tf' % (data_name, activation))\n",
    "\n",
    "    pred_Y, true_Y = model.predict(scaled_X, Y, final_model)\n",
    "\n",
    "    recall, auc_score, f_score, acc, precision = model.model_evaluation(pred_Y, true_Y)\n",
    "\n",
    "    res['activation'].append(activation)\n",
    "    res['data'].append(data_name)\n",
    "    res['precision'].append(precision)\n",
    "    res['auc_score'].append(auc_score)\n",
    "    res['acc'].append(acc)\n",
    "    res['f-score'].append(f_score)\n",
    "    res['recall'].append(recall)\n",
    "    res['weight'].append(loss_weight)\n",
    "\n",
    "    res_brier = pd.DataFrame.from_dict(res)\n",
    "    res_brier.to_csv('GEV_MODEL/' + 'result_final.csv', mode='a', encoding='euc-kr', index=False)\n",
    "\n",
    "    return res\n",
    "\n",
    "loss_weight = [0.05]\n",
    "training('gev', loss_weight, 'balanced_structureAll')\n",
    "\n",
    "\n",
    "def one_hot_encoding(data, variable):\n",
    "    values = data[variable].unique()\n",
    "    if len(values) == 2:\n",
    "        data[str(values[0])] = np.where(data[variable] == values[0], 1, 0)\n",
    "        data = data.drop(variable, axis=1)\n",
    "    else:\n",
    "        for val in values:\n",
    "            data[str(val)] = np.where(data[variable] == val, 1, 0)\n",
    "        data = data.drop(variable, axis=1)\n",
    "    return data\n",
    "\n",
    "new_test_data = pd.read_csv('test_structureAll.csv')\n",
    "\n",
    "Y_test = new_test_data['mace']\n",
    "X_test = new_test_data.drop('mace', axis=1)\n",
    "\n",
    "for var in list(X_test):\n",
    "    if X_test[var].dtype == 'object':\n",
    "        X_test = one_hot_encoding(X_test, var)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(X_test)\n",
    "scaled_X_test = scaler.transform(np.asarray(X_test))\n",
    "\n",
    "print(\"Shape of X_test after preprocessing: \", X_test.shape)\n",
    "\n",
    "model_path = 'GEV_MODEL/new_test/model_balanced_structureAll_gev.tf'\n",
    "final_model = load_model(model_path)\n",
    "\n",
    "pred_Y_list = final_model.predict([scaled_X_test, scaled_X_test])\n",
    "\n",
    "pred_Y_prob = pred_Y_list[1]\n",
    "\n",
    "pred_Y_prob = np.asarray(pred_Y_prob).flatten()\n",
    "\n",
    "pred_Y = np.where(pred_Y_prob >= 0.5, 1, 0)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, pred_Y)\n",
    "precision = precision_score(Y_test, pred_Y)\n",
    "recall = recall_score(Y_test, pred_Y)\n",
    "f1 = f1_score(Y_test, pred_Y)\n",
    "roc_auc = roc_auc_score(Y_test, pred_Y_prob)\n",
    "\n",
    "print(\"_____Test Set Evaluation Metrics_____\")\n",
    "print(\"Accuracy: %0.4f\" % accuracy)\n",
    "print(\"Precision: %0.4f\" % precision)\n",
    "print(\"Recall: %0.4f\" % recall)\n",
    "print(\"F1 Score: %0.4f\" % f1)\n",
    "print(\"ROC AUC: %0.4f\" % roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672bf8be-dd1f-44b1-ab91-271bdda5f7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
