{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332dafef-a1bc-4eb0-9d16-378f1a9b5456",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f2a9e0-1b0f-4474-97e5-2f25851e4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# 載入 BioBERT tokenizer 和 model  ( 從這邊替換bert、clinicalBert)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "\n",
    "# 定義一個函式來將文本轉換為向量\n",
    "def text_to_vector(text):\n",
    "    # 使用 tokenizer 將文本轉換為 token IDs\n",
    "    inputs = tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "    # 使用 BioBERT 模型將 token IDs 轉換為向量\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 取得 [CLS] token 的向量表示\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "\n",
    "    return cls_embedding\n",
    "\n",
    "# 將每個文本字段轉換為 BioBERT 向量\n",
    "for column in data.columns:\n",
    "    data[column] = data[column].astype(str)\n",
    "    data[column + '_vector'] = data[column].apply(text_to_vector)\n",
    "\n",
    "# 保存包含向量的 DataFrame 到新的 Excel 檔案\n",
    "data.to_excel('BioBERT.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff03fa9-ee35-4216-b9fa-f2d805e013e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BioGptModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model = BioGptModel.from_pretrained(\"microsoft/biogpt\")\n",
    "\n",
    "# 定義一個函式來將文本轉換為向量\n",
    "def text_to_vector(text):\n",
    "    # 使用 tokenizer 將文本轉換為 token IDs\n",
    "    inputs = tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "    # 使用 BioBERT 模型將 token IDs 轉換為向量\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 取得 [CLS] token 的向量表示\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "\n",
    "    return cls_embedding\n",
    "\n",
    "\n",
    "for column in data.columns:\n",
    "    data[column] = data[column].astype(str)\n",
    "    data[column + '_vector'] = data[column].apply(text_to_vector)\n",
    "\n",
    "\n",
    "data.to_excel('first_dr1.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
